{
  "stac_version": "1.0.0",
  "stac_extensions": [
    "https://stac-extensions.github.io/table/v1.2.0/schema.json"
  ],
  "type": "Feature",
  "id": "tg_tbats_temperature_P1D_scores",
  "bbox": [-149.6106, 18.1135, -66.7987, 68.6698],
  "geometry": {
    "type": "MultiPoint",
    "coordinates": [
      [-78.1473, 38.8943],
      [-96.6038, 39.1051],
      [-96.443, 38.9459],
      [-121.9338, 45.7908],
      [-89.4737, 46.2097],
      [-72.3295, 42.4719],
      [-149.143, 68.6698],
      [-82.0177, 29.6878],
      [-97.7823, 33.3785],
      [-82.0084, 29.676],
      [-105.9154, 39.8914],
      [-66.9868, 18.1135],
      [-111.7979, 40.7839],
      [-87.7982, 32.5415],
      [-66.7987, 18.1741],
      [-89.7048, 45.9983],
      [-99.1139, 47.1591],
      [-105.5442, 40.035],
      [-147.504, 65.1532],
      [-119.0274, 36.9559],
      [-111.5081, 33.751],
      [-88.1589, 31.8534],
      [-83.5038, 35.6904],
      [-102.4471, 39.7582],
      [-110.5871, 44.9501],
      [-122.1655, 44.2596],
      [-84.2793, 35.9574],
      [-84.4374, 31.1854],
      [-119.2575, 37.0597],
      [-87.4077, 32.9604],
      [-99.2531, 47.1298],
      [-149.6106, 68.6307],
      [-96.6242, 34.4442],
      [-77.9832, 39.0956]
    ]
  },
  "properties": {
    "title": "tg_tbats",
    "description": "All scores for the Daily_Water_temperature variable for the tg_tbats model. Information for the model is provided as follows: The tg_tbats model is a TBATS (Trigonometric seasonality, Box-Cox transformation, ARMA\nerrors, Trend and Seasonal components) model fit using the function tbats() from the forecast package in\nR (Hyndman et al. 2023; Hyndman et al., 2008). This is an empirical time series model with no\ncovariates..\n                                    The model predicts this variable at the following sites: POSE, KING, MCDI, MART, CRAM, HOPB, OKSR, SUGG, PRIN, BARC, WLOU, CUPE, REDB, BLWA, GUIL, LIRO, PRLA, COMO, CARI, TECR, SYCA, TOMB, LECO, ARIK, BLDE, MCRA, WALK, FLNT, BIGC, MAYF, PRPO, TOOK, BLUE, LEWI.\n                                    Scores are metrics that describe how well forecasts compare to observations. The scores catalog includes are summaries of the forecasts (i.e., mean, median, confidence intervals), matched observations (if available), and scores (metrics of how well the model distribution compares to observations)",
    "datetime": "2024-07-19",
    "updated": "2024-08-23",
    "start_datetime": "2022-08-06T00:00:00Z",
    "end_datetime": "2024-08-18T00:00:00Z",
    "providers": [
      {
        "url": "https://github.com/eco4cast/Forecast_submissions/blob/main/Generate_forecasts",
        "name": "Abigail Lewis",
        "roles": [
          "producer",
          "processor",
          "licensor"
        ]
      },
      {
        "url": "www.ecoforecast.org",
        "name": "Ecological Forecasting Initiative",
        "roles": [
          "host"
        ]
      }
    ],
    "license": "CC0-1.0",
    "keywords": [
      "Scores",
      "neon4cast",
      "Aquatics",
      "tg_tbats",
      "Water_temperature",
      "temperature",
      "Daily",
      "P1D",
      "POSE",
      "KING",
      "MCDI",
      "MART",
      "CRAM",
      "HOPB",
      "OKSR",
      "SUGG",
      "PRIN",
      "BARC",
      "WLOU",
      "CUPE",
      "REDB",
      "BLWA",
      "GUIL",
      "LIRO",
      "PRLA",
      "COMO",
      "CARI",
      "TECR",
      "SYCA",
      "TOMB",
      "LECO",
      "ARIK",
      "BLDE",
      "MCRA",
      "WALK",
      "FLNT",
      "BIGC",
      "MAYF",
      "PRPO",
      "TOOK",
      "BLUE",
      "LEWI"
    ],
    "table:columns": [
      {
        "name": "reference_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that the forecast was initiated (horizon = 0)"
      },
      {
        "name": "site_id",
        "type": "string",
        "description": "For forecasts that are not on a spatial grid, use of a site dimension that maps to a more detailed geometry (points, polygons, etc.) is allowable. In general this would be documented in the external metadata (e.g., alook-up table that provides lon and lat); however in netCDF this could be handled by the CF Discrete Sampling Geometry data model."
      },
      {
        "name": "datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime of the forecasted value (ISO 8601)"
      },
      {
        "name": "family",
        "type": "string",
        "description": "For ensembles: “ensemble.” Default value if unspecified For probability distributions: Name of the statistical distribution associated with the reported statistics. The “sample” distribution is synonymous with “ensemble.” For summary statistics: “summary.”If this dimension does not vary, it is permissible to specify family as a variable attribute if the file format being used supports this (e.g.,netCDF)."
      },
      {
        "name": "pub_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that forecast was submitted"
      },
      {
        "name": "observation",
        "type": "double",
        "description": "observed value for variable"
      },
      {
        "name": "crps",
        "type": "double",
        "description": "crps forecast score"
      },
      {
        "name": "logs",
        "type": "double",
        "description": "logs forecast score"
      },
      {
        "name": "mean",
        "type": "double",
        "description": "mean forecast prediction"
      },
      {
        "name": "median",
        "type": "double",
        "description": "median forecast prediction"
      },
      {
        "name": "sd",
        "type": "double",
        "description": "standard deviation forecasts"
      },
      {
        "name": "quantile97.5",
        "type": "double",
        "description": "upper 97.5 percentile value of forecast"
      },
      {
        "name": "quantile02.5",
        "type": "double",
        "description": "upper 2.5 percentile value of forecast"
      },
      {
        "name": "quantile90",
        "type": "double",
        "description": "upper 90 percentile value of forecast"
      },
      {
        "name": "quantile10",
        "type": "double",
        "description": "upper 10 percentile value of forecast"
      },
      {
        "name": "duration",
        "type": "string",
        "description": "temporal duration of forecast (hourly = PT1H, daily = P1D, etc.); follows ISO 8601 duration convention"
      },
      {
        "name": "model_id",
        "type": "string",
        "description": "unique model identifier"
      },
      {
        "name": "project_id",
        "type": "string",
        "description": "unique project identifier"
      }
    ]
  },
  "collection": "scores",
  "links": [
    {
      "rel": "collection",
      "href": "../collection.json",
      "type": "application/json",
      "title": "tg_tbats"
    },
    {
      "rel": "root",
      "href": "../../../catalog.json",
      "type": "application/json",
      "title": "Forecast Catalog"
    },
    {
      "rel": "parent",
      "href": "../collection.json",
      "type": "application/json",
      "title": "tg_tbats"
    },
    {
      "rel": "self",
      "href": "tg_tbats.json",
      "type": "application/json",
      "title": "Model Forecast"
    },
    {
      "rel": "item",
      "href": "https://github.com/eco4cast/Forecast_submissions/blob/main/Generate_forecasts",
      "type": "text/html",
      "title": "Link for Model Code"
    },
    {
      "rel": "item",
      "href": "https://radiantearth.github.io/stac-browser/#/external/raw.githubusercontent.com/eco4cast/neon4cast-ci/main/scores/Aquatics/Daily_Water_temperature/models/tg_tbats.json",
      "type": "text/html",
      "title": "Link for rendered STAC item"
    },
    {
      "rel": "item",
      "href": "https://raw.githubusercontent.com/eco4cast/neon4cast-ci/main/scores/Aquatics/Daily_Water_temperature/models/tg_tbats.json",
      "type": "text/html",
      "title": "Link for raw JSON file"
    }
  ],
  "assets": {
    "1": {
      "type": "application/json",
      "title": "Model Metadata",
      "href": "https://sdsc.osn.xsede.org/bio230014-bucket01/challenges/metadata/model_id/tg_tbats.json",
      "description": "Use `jsonlite::fromJSON()` to download the model metadata JSON file. This R code will return metadata provided during the model registration.\n      \n\n### R\n\n```{r}\n# Use code below\n\nmodel_metadata <- jsonlite::fromJSON(\"https://sdsc.osn.xsede.org/bio230014-bucket01/challenges/metadata/model_id/tg_tbats.json\")\n\n"
    },
    "2": {
      "type": "text/html",
      "title": "Link for Model Code",
      "href": "https://github.com/eco4cast/Forecast_submissions/blob/main/Generate_forecasts",
      "description": "The link to the model code provided by the model submission team"
    },
    "3": {
      "type": "text/plain",
      "title": "Model Sites",
      "href": "https://raw.githubusercontent.com/eco4cast/neon4cast-ci/main/neon4cast_field_site_metadata.csv",
      "description": "POSE, KING, MCDI, MART, CRAM, HOPB, OKSR, SUGG, PRIN, BARC, WLOU, CUPE, REDB, BLWA, GUIL, LIRO, PRLA, COMO, CARI, TECR, SYCA, TOMB, LECO, ARIK, BLDE, MCRA, WALK, FLNT, BIGC, MAYF, PRPO, TOOK, BLUE, LEWI"
    },
    "4": {
      "type": "application/x-parquet",
      "title": "Database Access for Daily Water_temperature",
      "href": "s3://anonymous@bio230014-bucket01/challenges/scores/bundled-parquet/project_id=neon4cast/duration=P1D/variable=temperature/model_id=tg_tbats?endpoint_override=sdsc.osn.xsede.org",
      "description": "Use `R` or `Python` code for remote access to the database. This code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(\"s3://anonymous@bio230014-bucket01/challenges/scores/bundled-parquet/project_id=neon4cast/duration=P1D/variable=temperature/model_id=tg_tbats?endpoint_override=sdsc.osn.xsede.org\")\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n### Python\n\n```{python}# Use code below\nimport ibis\ncon = ibis.duckdbf.connect()\ncon.raw_sql(f'''\nCREATE OR REPLACE SECRET secret (\nTYPE S3,\nENDPOINT 'sdsc.osn.xsede.org',\nURL_STYLE 'path'\n\n''');\npath = \"s3://bio230014-bucket01/challenges/scores/bundled-parquet/project_id=neon4cast/duration=P1D/variable=temperature/model_id=tg_tbats\"\ncon.read_parquet(path + \"/**\")"
    }
  }
}
